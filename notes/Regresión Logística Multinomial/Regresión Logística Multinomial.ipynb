{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión Logística Multinomial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algunas veces es necesario hacer clasificación para más de dos clases. Quizas se quiere clasificar tres formas de sentimientos (positivo, neutral o negativo). Esto se podría hacer analizando el contenido del habla y asignado un etiquetado semático a cada una de las palabras para poder valores el sentimiento del habla, sin embargo en esta publicación no vamos a hablar de esto por ahora. Vamos a dedicar la atención a la regresión logística multinomial o softmax."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En estas situaciones en donde es necesario hacer una clasificación para más de dos clases, se puede hacer uso de la **regresión logística multinomial**, o tambien **regresión softmax**. En este tipo de regresión la variable objetivo tiene un rango que varia sobre un conjunto de más de dos clases; el objetivo aquí será determinar cuá es la probabilidad de $y$ de pertenecer a cada una de las clases potenciales $c\\in C$, $P(y=c\\;|\\;x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La regresión logística multinomial clasifica usando una generalización de la función sigmoide, conocida como la función **softmax**, para calcular la probabilidad $P(y=c\\;|\\;x)$. La función softmax toma un vector $z=[z_1, z_2, \\dots, z_k]^{\\top}$ de $k$ valores arbitrarios y los mapea en una distribucción de probalicada, con cada valore en el rango $(0, 1)$, y todos los valores sumando uno. Como la función sigmoide. es una función exponencial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para un vector $z$ de dimensionalidad $k$, la función softmax es definida como:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$s(z_i)=\\frac{e^{z_i}}{\\sum_{j=1}^{k}e^{z_{j}}},\\; 1\\leq i\\leq k.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así, la función softmax de un vector $z=[z_1, z_2, \\dots, z_k]^{\\top}$ es por lo tanto una función vectorial:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$s(z)=\\left[\\frac{e^{z_1}}{\\sum_{j=1}^{k}e^{z_{1}}}, \\frac{e^{z_2}}{\\sum_{j=1}^{k}e^{z_{2}}},\\dots, \\frac{e^{z_k}}{\\sum_{j=1}^{k}e^{z_{k}}}\\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El denominador $\\frac{e^{z_i}}{\\sum_{j=1}^{k}e^{z_{j}}}$ es usado para normalizar todos los valores en probabilidades. Por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.array([0.6, 1.1, -1,5, 1.2, 3.2, -1.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01002305, 0.01652522, 0.00202362, 0.81638616, 0.01826319,\n",
       "       0.13494772, 0.00183105])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra vez como en la función sigmoide, la entrada de la función softmax puede ser el producto punto entre un vector de pesos $w=(w_0, \\dots, w_n)$ y un vector $x=(1, x_1,\\dots, x_n$. Pero ahora ese necesario separar el vector de pesos para cada una de las clases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(y=c\\;| \\;x)=\\frac{e^{w_c^\\top x}}{\\sum_{j=1}^{k}e^{w_j^\\top x}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como la función sigmoide, la función softmax tiene la propiedad de transformar los valores hacía $0$ o $1$. Pos lo tanto , si una de las entradas es más grande que los otros, tenderá a aumentar su probabilidad hacia $1$, y suprime las probabilidades de las entradas más pequeñas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicaciones de la regresión logística multinomial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la clasificación de los datos de entrada es necesario definir una función que depende de la observación $x$ y de la potencial clase $c$. Para esto se usará la notación $f_i(c, x)$, que indicará el atributo $i$ para una clases particular $c$ dado por la observación $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En clasificación binaria, un peso positivo en una característica apunta hacia $y = 1$ y\n",
    "un peso negativo hacia $y = 0$, pero en la clasificación multiclase una característica podría ser\n",
    "evidencia a favor o en contra de una clase individual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos algunas características de muestra para algunas tareas de PNL para ayudar a comprender este uso quizás poco intuitivo de características que son funciones tanto de la observación $x$ como de la clase $c$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supongamos que estamos haciendo una clasificación de texto y, en lugar de una clasificación binaria, nuestra tarea es asignar una de las 3 clases A, B o C (neutral) a un documento. Ahora, una función relacionada con los signos de exclamación puede tener un peso negativo para C documentos y un peso positivo para documentos A o B:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$f_1(C, x)=\\begin{cases}1 & \\mbox{ si } ! \\notin doc \\\\\n",
    "0 & \\mbox{ si } ! \\in doc \n",
    "\\end{cases},\\;w_1 = -4.5$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$f_2(A, x)=\\begin{cases}1 & \\mbox{ si } ! \\notin doc \\\\\n",
    "0 & \\mbox{ si } ! \\in doc \n",
    "\\end{cases},\\;w_1 = 2.6$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$f_3(B, x)=\\begin{cases}1 & \\mbox{ si } ! \\notin doc \\\\\n",
    "0 & \\mbox{ si } ! \\in doc \n",
    "\\end{cases},\\;w_1 = 1.3$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Cómo aprende las regresión multinomial logística?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La regresión logística multinomial tiene una función de pérdida ligeramente diferente a la regresión logística binaria porque utiliza el clasificador softmax en lugar del sigmoide. La función de pérdida para un solo ejemplo $x$ es la suma de los registros de las $k$ clases de salida:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$L_{CE}(\\hat{y}, y)=-\\sum_{h=1}^{k}\\mathbb{1}_{\\{y=k\\}}\\log P(y=k\\;|\\;x)=-\\sum_{k=1}^{k}\\mathbb{1}_{\\{y=k\\}}\\log \\frac{e^{w_{k}\\cdot x + b_{k}}}{\\sum_{j=1}^{k}e^{w_j\\cdot x + b_{j}}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La expersión $\\mathbb{1}_{\\{y=k\\}}$ toma el valor de uno cuando la condición en las llaves es verdadera y cero en cualquier otro caso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El gradiente para una muestra es muy similar a el gradiente para la regresión logistica, aunque no se mostrará aquí la derivación. Es la diferencia entre el valor de la clase verdadera $k$ y la probabilidad que el clasificador genera para la clase $k$, ponderada por el valor de la entrada $x_{k}$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial L_{CE}}{\\partial w_{k}} = -(\\mathbb{1}_{\\{y=k\\}}-P(y=k\\;|\\;x))x_{k}=-\\left(\\mathbb{1}_{\\{y=k\\}} - \\frac{e^{w_{k}\\cdot x + b_{k}}}{\\sum_{j=1}^{k}e^{w_j\\cdot x + b_{j}}}\\right)x_k$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementación con Tensorflow - MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST es un conjunto de datos de digitos escritos a mano que se en muchos ejemplos introductorios al machine learning. El conjunto de datos contiene 60000 ejemplos para entrenamiento y 10000 ejemplos para testeo. El tamaño de los digitos ha sido normalizado y la imagen centrada (28 x 28 pixeles) con valores de 0 a 1. Por simplicidad, cada imagen ha sido convertido es una matriz númerica 1-D de 784 características (28 x 28). Para más información [http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para nuestro ejemplo de regresión logística multinomial usaremos TensorFlow V2 y se implementará a bajo nivel para entender los detalles que hay en el proceso de entrenamiento. Los detalles de este ejemplo se puede encontrar en [TensorFlow Examples - GitHub](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/2_BasicModels/logistic_regression.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se definen las características generales de los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "num_features = 784"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También se definen los parámetros de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "training_steps = 1000 \n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lectura de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se cargan los datos y se identifican el conjunto de entrenamiento y el de testeo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para visualizar algunos ejemplos hacemos uso de `matplotlib`  de la siguiente forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[5], cmap='gray')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparación de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estadarización del tipo de dato:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = np.array(x_train, np.float32), np.array(x_test, np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformación de los datos a vectores de 784 características:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = x_train.reshape([-1, num_features]), x_test.reshape([-1, num_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalización de los datos de [0, 255] a [0, 1]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = x_train / 255., x_test / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación particionamos los datos por lotes y los mezclamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_data = train_data.repeat().shuffle(5000).batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construcción del módelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.ones([num_features, num_classes]), name=\"weight\")\n",
    "b = tf.Variable(tf.zeros([num_classes]), name=\"bias\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regresión logistica de (Wx + b):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(x):\n",
    "    return tf.nn.softmax(tf.matmul(x, W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función de costo en este caso sería:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(y_pred, y_true):\n",
    "    y_true = tf.one_hot(y_true, depth=num_classes)\n",
    "    y_pred = tf.clip_by_value(y_pred, 1e-9, 0.9)\n",
    "    return tf.reduce_mean(-tf.reduce_sum(y_true * tf.math.log(y_pred) + (1 - y_true) * tf.math.log(1 - y_pred),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La medida que se usará para determinar la calidad del modelo será:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y_true):\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.cast(y_true, tf.int64))\n",
    "    return tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para entrenar el modelo, se utilizará el optimizador definido para el gradiente estocástico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.optimizers.SGD(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_optimization(x, y):\n",
    "    with tf.GradientTape() as g:\n",
    "        pred = logistic_regression(x)\n",
    "        loss = cross_entropy(pred, y)\n",
    "    \n",
    "    gradients = g.gradient(loss, [W, b])\n",
    "    \n",
    "    optimizer.apply_gradients(zip(gradients, [W, b]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se ejecuta el proceso de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 50, loss: 2.691798, accuracy: 0.707031\n",
      "step: 100, loss: 2.201120, accuracy: 0.742188\n",
      "step: 150, loss: 1.926627, accuracy: 0.789062\n",
      "step: 200, loss: 1.788280, accuracy: 0.773438\n",
      "step: 250, loss: 1.502035, accuracy: 0.812500\n",
      "step: 300, loss: 1.421701, accuracy: 0.812500\n",
      "step: 350, loss: 1.371978, accuracy: 0.847656\n",
      "step: 400, loss: 1.382541, accuracy: 0.789062\n",
      "step: 450, loss: 1.242893, accuracy: 0.847656\n",
      "step: 500, loss: 1.199832, accuracy: 0.839844\n",
      "step: 550, loss: 1.111963, accuracy: 0.855469\n",
      "step: 600, loss: 1.156131, accuracy: 0.828125\n",
      "step: 650, loss: 1.010465, accuracy: 0.871094\n",
      "step: 700, loss: 0.882333, accuracy: 0.914062\n",
      "step: 750, loss: 1.011202, accuracy: 0.863281\n",
      "step: 800, loss: 0.971723, accuracy: 0.855469\n",
      "step: 850, loss: 1.082722, accuracy: 0.832031\n",
      "step: 900, loss: 0.912813, accuracy: 0.875000\n",
      "step: 950, loss: 0.927843, accuracy: 0.863281\n",
      "step: 1000, loss: 1.057235, accuracy: 0.820312\n"
     ]
    }
   ],
   "source": [
    "display_step = 50\n",
    "for step, (batch_x, batch_y) in enumerate(train_data.take(training_steps), 1):\n",
    "    run_optimization(batch_x, batch_y)\n",
    "    \n",
    "    if step % display_step == 0:\n",
    "        pred = logistic_regression(batch_x)\n",
    "        loss = cross_entropy(pred, batch_y)\n",
    "        acc = accuracy(pred, batch_y)\n",
    "        print('step: %i, loss: %f, accuracy: %f' % (step, loss, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente se valida el modelo y se visualizan los resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.877100\n"
     ]
    }
   ],
   "source": [
    "pred = logistic_regression(x_test)\n",
    "print(\"Test Accuracy: %f\" % accuracy(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAM20lEQVR4nO3dXahc9bnH8d/vpCmI6UXiS9ik0bTBC8tBEo1BSCxbQktOvIjFIM1FyYHi7kWUFkuo2It4WaQv1JvALkrTkmMJpGoQscmJxVDU4o5Es2NIjCGaxLxYIjQRJMY+vdjLso0za8ZZa2ZN8nw/sJmZ9cya9bDMz7VmvczfESEAV77/aroBAINB2IEkCDuQBGEHkiDsQBJfGeTCbHPoH+iziHCr6ZW27LZX2j5o+7Dth6t8FoD+cq/n2W3PkHRI0nckHZf0mqS1EfFWyTxs2YE+68eWfamkwxFxJCIuSPqTpNUVPg9AH1UJ+zxJx6a9Pl5M+xzbY7YnbE9UWBaAivp+gC4ixiWNS+zGA02qsmU/IWn+tNdfL6YBGEJVwv6apJtsf8P2VyV9X9L2etoCULeed+Mj4qLtByT9RdIMSU9GxP7aOgNQq55PvfW0ML6zA33Xl4tqAFw+CDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJ9Dw+uyTZPirpnKRPJV2MiCV1NAWgfpXCXrgrIv5Rw+cA6CN244EkqoY9JO2wvcf2WKs32B6zPWF7ouKyAFTgiOh9ZnteRJywfb2knZIejIjdJe/vfWEAuhIRbjW90pY9Ik4Uj2ckPS1paZXPA9A/PYfd9tW2v/bZc0nflTRZV2MA6lXlaPxcSU/b/uxz/i8iXqilKwC1q/Sd/UsvjO/sQN/15Ts7gMsHYQeSIOxAEoQdSIKwA0nUcSNMCmvWrGlbu//++0vnff/990vrH3/8cWl9y5YtpfVTp061rR0+fLh0XuTBlh1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkuCuty4dOXKkbW3BggWDa6SFc+fOta3t379/gJ0Ml+PHj7etPfbYY6XzTkxcvr+ixl1vQHKEHUiCsANJEHYgCcIOJEHYgSQIO5AE97N3qeye9VtuuaV03gMHDpTWb7755tL6rbfeWlofHR1tW7vjjjtK5z127Fhpff78+aX1Ki5evFha/+CDD0rrIyMjPS/7vffeK61fzufZ22HLDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJcD/7FWD27Nlta4sWLSqdd8+ePaX122+/vZeWutLp9/IPHTpUWu90/cKcOXPa1tavX18676ZNm0rrw6zn+9ltP2n7jO3JadPm2N5p++3isf2/NgBDoZvd+N9LWnnJtIcl7YqImyTtKl4DGGIdwx4RuyWdvWTyakmbi+ebJd1Tb1sA6tbrtfFzI+Jk8fyUpLnt3mh7TNJYj8sBUJPKN8JERJQdeIuIcUnjEgfogCb1eurttO0RSSoez9TXEoB+6DXs2yWtK56vk/RsPe0A6JeO59ltPyVpVNK1kk5L2ijpGUlbJd0g6V1J90XEpQfxWn0Wu/Ho2r333lta37p1a2l9cnKybe2uu+4qnffs2Y7/nIdWu/PsHb+zR8TaNqUVlToCMFBcLgskQdiBJAg7kARhB5Ig7EAS3OKKxlx//fWl9X379lWaf82aNW1r27ZtK533csaQzUByhB1IgrADSRB2IAnCDiRB2IEkCDuQBEM2ozGdfs75uuuuK61/+OGHpfWDBw9+6Z6uZGzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJ7mdHXy1btqxt7cUXXyydd+bMmaX10dHR0vru3btL61cq7mcHkiPsQBKEHUiCsANJEHYgCcIOJEHYgSS4nx19tWrVqra1TufRd+3aVVp/5ZVXeuopq45bdttP2j5je3LatEdtn7C9t/hr/18UwFDoZjf+95JWtpj+m4hYVPw9X29bAOrWMewRsVvS2QH0AqCPqhyge8D2m8Vu/ux2b7I9ZnvC9kSFZQGoqNewb5K0UNIiSScl/ardGyNiPCKWRMSSHpcFoAY9hT0iTkfEpxHxL0m/k7S03rYA1K2nsNsemfbye5Im270XwHDoeJ7d9lOSRiVda/u4pI2SRm0vkhSSjkr6Uf9axDC76qqrSusrV7Y6kTPlwoULpfNu3LixtP7JJ5+U1vF5HcMeEWtbTH6iD70A6CMulwWSIOxAEoQdSIKwA0kQdiAJbnFFJRs2bCitL168uG3thRdeKJ335Zdf7qkntMaWHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSYMhmlLr77rtL688880xp/aOPPmpbK7v9VZJeffXV0jpaY8hmIDnCDiRB2IEkCDuQBGEHkiDsQBKEHUiC+9mTu+aaa0rrjz/+eGl9xowZpfXnn28/5ifn0QeLLTuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJMH97Fe4TufBO53rvu2220rr77zzTmm97J71TvOiNz3fz257vu2/2n7L9n7bPy6mz7G90/bbxePsupsGUJ9uduMvSvppRHxL0h2S1tv+lqSHJe2KiJsk7SpeAxhSHcMeEScj4vXi+TlJByTNk7Ra0ubibZsl3dOnHgHU4EtdG297gaTFkv4uaW5EnCxKpyTNbTPPmKSxCj0CqEHXR+Ntz5K0TdJPIuKf02sxdZSv5cG3iBiPiCURsaRSpwAq6SrstmdqKuhbIuLPxeTTtkeK+oikM/1pEUAdOu7G27akJyQdiIhfTyttl7RO0i+Kx2f70iEqWbhwYWm906m1Th566KHSOqfXhkc339mXSfqBpH229xbTHtFUyLfa/qGkdyXd15cOAdSiY9gj4m+SWp6kl7Si3nYA9AuXywJJEHYgCcIOJEHYgSQIO5AEPyV9Bbjxxhvb1nbs2FHpszds2FBaf+655yp9PgaHLTuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJMF59ivA2Fj7X/264YYbKn32Sy+9VFof5E+Roxq27EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBOfZLwPLly8vrT/44IMD6gSXM7bsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5BEN+Ozz5f0B0lzJYWk8Yj4re1HJd0v6YPirY9ExPP9ajSzO++8s7Q+a9asnj+70/jp58+f7/mzMVy6uajmoqSfRsTrtr8maY/tnUXtNxHxy/61B6Au3YzPflLSyeL5OdsHJM3rd2MA6vWlvrPbXiBpsaS/F5MesP2m7Sdtz24zz5jtCdsT1VoFUEXXYbc9S9I2ST+JiH9K2iRpoaRFmtry/6rVfBExHhFLImJJ9XYB9KqrsNueqamgb4mIP0tSRJyOiE8j4l+Sfidpaf/aBFBVx7DbtqQnJB2IiF9Pmz4y7W3fkzRZf3sA6tLN0fhlkn4gaZ/tvcW0RySttb1IU6fjjkr6UR/6Q0VvvPFGaX3FihWl9bNnz9bZDhrUzdH4v0lyixLn1IHLCFfQAUkQdiAJwg4kQdiBJAg7kARhB5LwIIfctc34vkCfRUSrU+Vs2YEsCDuQBGEHkiDsQBKEHUiCsANJEHYgiUEP2fwPSe9Oe31tMW0YDWtvw9qXRG+9qrO3G9sVBnpRzRcWbk8M62/TDWtvw9qXRG+9GlRv7MYDSRB2IImmwz7e8PLLDGtvw9qXRG+9GkhvjX5nBzA4TW/ZAQwIYQeSaCTstlfaPmj7sO2Hm+ihHdtHbe+zvbfp8emKMfTO2J6cNm2O7Z223y4eW46x11Bvj9o+Uay7vbZXNdTbfNt/tf2W7f22f1xMb3TdlfQ1kPU28O/stmdIOiTpO5KOS3pN0tqIeGugjbRh+6ikJRHR+AUYtr8t6bykP0TEfxfTHpN0NiJ+UfyPcnZE/GxIentU0vmmh/EuRisamT7MuKR7JP2vGlx3JX3dpwGstya27EslHY6IIxFxQdKfJK1uoI+hFxG7JV06JMtqSZuL55s19Y9l4Nr0NhQi4mREvF48Pyfps2HGG113JX0NRBNhnyfp2LTXxzVc472HpB2299gea7qZFuZGxMni+SlJc5tspoWOw3gP0iXDjA/Nuutl+POqOED3Rcsj4lZJ/yNpfbG7OpRi6jvYMJ077WoY70FpMcz4fzS57nod/ryqJsJ+QtL8aa+/XkwbChFxong8I+lpDd9Q1Kc/G0G3eDzTcD//MUzDeLcaZlxDsO6aHP68ibC/Jukm29+w/VVJ35e0vYE+vsD21cWBE9m+WtJ3NXxDUW+XtK54vk7Ssw328jnDMox3u2HG1fC6a3z484gY+J+kVZo6Iv+OpJ830UObvr4p6Y3ib3/TvUl6SlO7dZ9o6tjGDyVdI2mXpLcl/b+kOUPU2x8l7ZP0pqaCNdJQb8s1tYv+pqS9xd+qptddSV8DWW9cLgskwQE6IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUji3y9hG/l2EQpSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model prediction: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model prediction: 2\n"
     ]
    }
   ],
   "source": [
    "n_images = 2\n",
    "test_images = x_test[:n_images]\n",
    "predictions = logistic_regression(test_images)\n",
    "\n",
    "for i in range(n_images):\n",
    "    plt.imshow(np.reshape(test_images[i], [28, 28]), cmap='gray')\n",
    "    plt.show()\n",
    "    print(\"Model prediction: %i\" % np.argmax(predictions.numpy()[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta ocasión se introduccido los aspectos generales de la regresión logistica multinomial como un modelo de clasificación:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* La regresión logística multinomial se puede utilizar con dos clases (por ejemplo determinar si un sentimiento es positivo o negativo) o con múltiples clases (por ejemplo la clasificación de libros de acuerdo con un genero literario).\n",
    "* Se usa la función softmax para calcular probabilidades."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliografía\n",
    "* Mustafa Murat Arat. 2019. [Logistic Regression in Tensorflow](https://mmuratarat.github.io/2019-01-07/logistic-regression-in-Tensorflow).\n",
    "* [Andrew Ng](https://www.andrewng.org). [Machine learning course materials](http://cs229.stanford.edu/materials.html). Technical report, University of Stanford.\n",
    "* Aurelien Geron. 2019. Hands-on Machine Learning with Scikit-Learn, Keras and TensorFlow.\n",
    "* Aymeric Damien. [TensorFlow Tutorial and Examples for Beginners (support TF v1 & v2)](https://github.com/aymericdamien/TensorFlow-Examples)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contacto\n",
    "* Participa de la canal de Nerve a través de [Discord](https://discord.gg/edPmghPq8K).\n",
    "* Se quieres conocer más acerca de este tema me puedes contactar a través de [Classgap](https://www.classgap.com/me/alejandro-sanchez-yali)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.8.0",
   "language": "python",
   "name": "3.8.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
