{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differentiation\n",
    "**Author:** Alejandro Sánchez Yalí\n",
    "\n",
    "In this chapter, we review key differentiation concepts. In particular, we emphasize on the fundamental role played by\n",
    "linear approximations in the context of numerical differentiation. We also discuss the concept of automatic\n",
    "differentiation, which is a powerful tool for computing derivatives of functions implemented in computer programs.\n",
    "\n",
    "## Univariate differentiation\n",
    "### Derivatives\n",
    "Before studying derivatives, we recall the definition of function continuity.\n",
    "\n",
    "<div class=\"definition\"><p>Definition 1.1. Continuous function</p> \n",
    "  <P>A function $f: \\mathbb{R} \\rightarrow \\mathbb{R}$ is continuous at a point $x_0$ if $$\\lim_{x \\to x_0} f(x) = f(x_0).$$\n",
    "  A function $f$ is continuous if it is continuous at every point in its domain.</p>\n",
    "</div>\n",
    "\n",
    "In the following, we use Landau's notation to describe the behavior of functions near a point. We write $$f(x) = o\\big(g(x)\\big) \\quad \\text{as} \\quad x \\to x_0$$\n",
    "if $$\\lim_{x \\to x_0} \\frac{|f(x)|}{|g(x)|} = 0.$$\n",
    "\n",
    "That is, $f(x)$ is much smaller than $g(x)$ as $x$ approaches $x_0.$ For example, $f$ is continuous at $x_0$ \n",
    "if $$f(x_0 + \\delta) = f(x_0) + o(1) \\quad \\text{as} \\quad \\delta \\to 0.$$\n",
    "\n",
    "We now introduce the concept of derivative. Consider a function $f: \\mathbb{R} \\rightarrow \\mathbb{R}$ and a point\n",
    "$x_0$ in its domain. Its value on an interval $[x_0, x_0 + h]$ can be approximated by the secant between $\\big(x_0, f(x_0)\\big)$\n",
    "and $\\big(x_0 + h, f(x_0 + h)\\big)$. The slope of this **secant** is given by the difference quotient $$\\frac{f(x_0 + h) -\n",
    "f(x_0)}{h}.$$ In the limit of an infinitesimal $h$, the secant converges to the **tangent** at $\\big(x_0, f(x_0)\\big)$. The slope\n",
    "of this tangent is the derivative of $f$ at $x_0$, denoted by $f'(x_0).$ The definition below\n",
    "formalizes this intuition.\n",
    "\n",
    "<div class=\"definition\"><p>Definition 1.2. Derivative</p>\n",
    "  <p>The derivative of a function $f: \\mathbb{R} \\rightarrow \\mathbb{R}$ at a point $x_0$ is defined as \n",
    "  $$f'(x_0) = \\lim_{h \\to 0} \\frac{f(x_0 + h) - f(x_0)}{h}.$$ If $f'(x_0)$ is well-defined at a particular $x_0$, \n",
    "  we say that the function $f$ is differentiable at $x_0$.</p>\n",
    "</div>\n",
    "\n",
    "Here, and in the following definitions, if $f$ is differentiable at any $x$, we say that it is **differentiable\n",
    "everywhere** of simply **differentiable**. If $f$ is differentiable at a given $x$, then it is necessarily continuous at\n",
    "$x$.\n",
    "\n",
    "<div class=\"theorem\"><p>Theorem 1.1. Differentiability implies continuity</p> \n",
    "  <P>If a function $f: \\mathbb{R} \\rightarrow \\mathbb{R}$ is differentiable at a point $x_0$, then it is continuous at $x_0$.\n",
    "  </p>\n",
    "</div>\n",
    "\n",
    "*Proof.* The proof follows from the definition of derivative. We have $$f(x_0 + h) = f(x_0) + f'(x_0)h + o(h) \\quad\n",
    "\\text{as} \\quad h \\to 0.$$ Since $f'(x_0)h + o(h) = o(1)$ as $h \\to 0$, we have that  $$\\lim_{h \\to 0} |f(x_0 + h) -\n",
    "f(x_0)| = 0.$$ Therefore, $f$ is continuous at $x_0$.\n",
    "\n",
    "In addition to enabling the computation of the slope of a function at a point, the derivative provides information about\n",
    "the **mononicity** of $f$ near that point. For example, if $f'(x_0) > 0$, then $f$ is increasing near $x_0$. If $f'(x_0) < 0$,\n",
    "then $f$ is decreasing near $x_0$. If $f'(x_0) = 0$, then $f$ has a local extremum at $x_0$. Such information can be\n",
    "used to develop iterative algorithms to minimize or maximize $f$ by computing iterates of the form $$x_{n+1} = x_n - \\alpha f'(x_n),$$\n",
    "where $\\alpha$ is a step size. If $\\alpha > 0$, the algorithm converges to a local minimum of $f$. If $\\alpha < 0,$ it\n",
    "converges to a local maximum. If $f$ is convex, the algorithm converges to the global minimum. \n",
    "\n",
    "For several elementary functions, the derivative can be computed analytically. \n",
    "\n",
    "<div class=\"example\"><p>Example 1.1. Derivative of power function</p> \n",
    "  <P>The derivative of $f(x) = x^n$ for $x \\in \\mathbb{R}$ and $n \\in \\mathbb{N}\\setminus \\{0\\}$ is given by $f'(x) = nx^{n-1}$. In fact, we consider $f(x) = x^n$ for $x \\in \\mathbb{R}$ and $n \\in \\mathbb{N}\\setminus \\{0\\}$. We have $$\\begin{equation}f(x + h) = (x + h)^n = \\sum_{k=0}^n \\binom{n}{k} x^{n-k} h^k\\end{equation}$$ Therefore, $$\\begin{equation}\\begin{split}f(x + h) - f(x) & = \\sum_{k=0}^n \\binom{n}{k} x^{n-k} h^k - x^n \\\\ & = \\sum_{k=1}^n \\binom{n}{k} x^{n-k} h^k.\\end{split}\\end{equation}$$ Dividing by $h$ and taking the limit as $h \\to 0$, we obtain $$\\begin{equation}\\begin{split}f'(x) & = \\lim_{h \\to 0} \\frac{f(x + h) - f(x)}{h} \\\\ & = \\lim_{h \\to 0} \\sum_{k=1}^n \\binom{n}{k} x^{n-k} h^{k-1} \\\\ & = nx^{n-1}.\\end{split}\\end{equation}$$\n",
    "  </p>\n",
    "</div>\n",
    "<div class=\"remark\"><p>Remark 1.1. Functions on a subset $U$ of $\\mathbb{R}$</p> \n",
    "  <P>For simplicity, we consider functions $f: \\mathbb{R} \\rightarrow \\mathbb{R}.$ However, the concept of derivative can be extended to functions defined on a subset $U$ of $\\mathbb{R}.$ If a fuction $f: U \\rightarrow \\mathbb{R}$ is defined on a subset $U$ of $\\mathbb{R}$, as it is the case for $f(x) = \\sqrt{x}$, defined on $U=\\mathbb{R}^+,$ the derivative of $f$ at a point $x_0 \\in U$ is defined on a neighborhood of $x_0$ contained in $U$, that is, there exist $r > 0$ such that $f$ is differentiable on $x_0 + \\epsilon \\in U$ for all $|\\epsilon| < r.$ The function $f$ is then said **differentiable everywhere** or differentiable for short if it is differentiable at every point in the **interior** of $U$, the set of points in $U$ such that $\\{x + \\epsilon: |\\epsilon| < r\\} \\subset U$ for some $r > 0$. For points lying at the boundary of $U$, the concept of derivative is more subtle and requires the definition of **one-sided derivatives**, meaning that the limit in the definition of derivative is taken from the left or from the right. For example, the derivative of $f(x) = \\sqrt{x}$ at $x=0$ is not defined, since the function is not defined for negative values of $x$. However, the derivative of $f(x) = \\sqrt{x}$ at $x=0$ is defined from the right, and it is equal to $1/2.$</p>\n",
    "</div>\n",
    "\n",
    "### Calculus rules\n",
    "\n",
    "For a given $x \\in \\mathbb{R}$ and two functions $f:\\mathbb{R}\\to\\mathbb{R}$ and $g:\\mathbb{R}\\to \\mathbb{R},$ the\n",
    "derivative of elementary operations on $f$ and $g$ such as their sums, products or compositions can easily be derived\n",
    "from the definition of the derivative, under appropriate conditions on the differentiability properties of $f$ and $g$\n",
    "at $x$. For example, if the functions $f$ and $g$ are differentiable at $x,$ then the sum $af + bg$ and the product $fg$\n",
    "are differentiable at $x$ for any $a, b \\in \\mathbb{R}$, and their derivatives are given by \n",
    "\n",
    "1. Linearity: $(af + bg)'(x) = af'(x) + bg'(x).$\n",
    " \n",
    "2. Product rule: $(fg)'(x) = f'(x)g(x) + f(x)g'(x),$ where $(fg)(x) + f(x)g(x).$\n",
    "\n",
    "The linearity can be verified directly from the linearity of the limit operator. For the product rule, we have\n",
    "\n",
    "<div class=\"non-display-mobile\">\n",
    "$$\\begin{equation}\\begin{split} \\frac{(fg)(x + h) - (fg)(x)}{h} & = \\frac{f(x+h)g(x + h) - \\color{red}{f(x)g(x + h)}}{h} \\\\ & + \\frac{{\\color{red}f(x)g(x + h)} - fg(x)}{h} \\\\ & = g(x + h) \\frac{f(x + h) - f(x)}{h} \\\\ & + f(x)\n",
    "\\frac{g(x + h) - g(x)}{h}.\\end{split}\\end{equation}$$\n",
    "</div>\n",
    "\n",
    "<div class=\"non-display-desktop\">\n",
    "$$\\begin{equation}\\begin{split} & \\frac{(fg)(x + h) - (fg)(x)}{h} = \\\\ & = \\frac{f(x+h)g(x + h) - \\color{red}{f(x)g(x + h)}}{h} \\\\ & + \\frac{{\\color{red}f(x)g(x + h)} - f(x)g(x)}{h} \\\\ & = g(x + h) \\frac{f(x + h) - f(x)}{h} \\\\ & + f(x)\n",
    "\\frac{g(x + h) - g(x)}{h}.\\end{split}\\end{equation}$$\n",
    "</div>\n",
    "\n",
    "If the derivatives of $g$ at $x$ and of $f$ at $g(x)$ exist, then the derivative of the composition $(f\\circ g)(x) =\n",
    "f(g(x))$ at $x$ is given by the **chain rule**:\n",
    "\n",
    "3. Chain rule: $(f\\circ g)'(x) = f'(g(x))g'(x).$\n",
    "\n",
    "The chain rule can be derived by considering the limit of the difference quotient of the composition $(f\\circ g)(x)$ as\n",
    "$h \\to 0$:\n",
    "\n",
    "<div class=\"non-display-mobile\">\n",
    "$$\\begin{equation}\\begin{split} \\frac{(f\\circ g)(x + h) - (f\\circ g)(x)}{h} & = \\frac{f(g(x + h)) - f(g(x))}{h} \\\\ & = \\frac{f(g(x + h)) - f(g(x))}{g(x + h) - g(x)} \\frac{g(x + h) - g(x)}{h}.\\end{split}\\end{equation}$$\n",
    "</div>\n",
    "\n",
    "<div class=\"non-display-desktop\">\n",
    "$$\\begin{equation}\\begin{split} & \\frac{(f\\circ g)(x + h) - (f\\circ g)(x)}{h} = \\\\ & = \\frac{f(g(x + h)) - f(g(x))}{h} \\\\ & = \\frac{f(g(x + h)) - f(g(x))}{g(x + h) - g(x)} \\frac{g(x + h) - g(x)}{h}.\\end{split}\\end{equation}$$\n",
    "</div>\n",
    "\n",
    "As seen in the sequel, the linearity and the product rule can be seen as byproducts of the chain rule, making the chain\n",
    "rule the cornerstone of differentiation.\n",
    "\n",
    "For now, consider a function that can be expressed as sums, products aor compositions of elementary functions such as\n",
    "$f(x) = \\exp(x) \\ln(x) + \\cos x^2.$ Its derivative can be computed by applying the aforementioned rules on the\n",
    "decomposition of $f$ into elementary operations and functions. \n",
    "\n",
    "\n",
    "<div class=\"example\"><p>Example 1.2. Applying rules of differentiation</p> \n",
    "  <P>Consider the function $f(x) = \\exp(x) \\ln(x) + \\cos x^2.$ We have $$f'(x) = \\exp(x) \\ln(x) + \\exp(x) \\frac{1}{x} - 2x \\sin x^2.$$ The derivative of $f$ on $x > 0$ can be computed step by step as follows, denoting $\\operatorname*{sq}(x) := x^2$,\n",
    "\n",
    "  </p>$\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differentiation\n",
    "**Author:** Alejandro Sánchez Yalí\n",
    "\n",
    "In this chapter, we review key differentiation concepts. In particular, we emphasize on the fundamental role played by\n",
    "linear approximations in the context of numerical differentiation. We also discuss the concept of automatic\n",
    "differentiation, which is a powerful tool for computing derivatives of functions implemented in computer programs.\n",
    "\n",
    "## Univariate differentiation\n",
    "### Derivatives\n",
    "Before studying derivatives, we recall the definition of function continuity.\n",
    "\n",
    "<div class=\"definition\"><p>Definition 1.1. Continuous function</p> \n",
    "  <P>A function $f: \\mathbb{R} \\rightarrow \\mathbb{R}$ is continuous at a point $x_0$ if $$\\lim_{x \\to x_0} f(x) = f(x_0).$$\n",
    "  A function $f$ is continuous if it is continuous at every point in its domain.</p>\n",
    "</div>\n",
    "\n",
    "In the following, we use Landau's notation to describe the behavior of functions near a point. We write $$f(x) = o\\big(g(x)\\big) \\quad \\text{as} \\quad x \\to x_0$$\n",
    "if $$\\lim_{x \\to x_0} \\frac{|f(x)|}{|g(x)|} = 0.$$\n",
    "\n",
    "That is, $f(x)$ is much smaller than $g(x)$ as $x$ approaches $x_0.$ For example, $f$ is continuous at $x_0$ \n",
    "if $$f(x_0 + \\delta) = f(x_0) + o(1) \\quad \\text{as} \\quad \\delta \\to 0.$$\n",
    "\n",
    "We now introduce the concept of derivative. Consider a function $f: \\mathbb{R} \\rightarrow \\mathbb{R}$ and a point\n",
    "$x_0$ in its domain. Its value on an interval $[x_0, x_0 + h]$ can be approximated by the secant between $\\big(x_0, f(x_0)\\big)$\n",
    "and $\\big(x_0 + h, f(x_0 + h)\\big)$. The slope of this **secant** is given by the difference quotient $$\\frac{f(x_0 + h) -\n",
    "f(x_0)}{h}.$$ In the limit of an infinitesimal $h$, the secant converges to the **tangent** at $\\big(x_0, f(x_0)\\big)$. The slope\n",
    "of this tangent is the derivative of $f$ at $x_0$, denoted by $f'(x_0).$ The definition below\n",
    "formalizes this intuition.\n",
    "\n",
    "<div class=\"definition\"><p>Definition 1.2. Derivative</p>\n",
    "  <p>The derivative of a function $f: \\mathbb{R} \\rightarrow \\mathbb{R}$ at a point $x_0$ is defined as \n",
    "  $$f'(x_0) = \\lim_{h \\to 0} \\frac{f(x_0 + h) - f(x_0)}{h}.$$ If $f'(x_0)$ is well-defined at a particular $x_0$, \n",
    "  we say that the function $f$ is differentiable at $x_0$.</p>\n",
    "</div>\n",
    "\n",
    "Here, and in the following definitions, if $f$ is differentiable at any $x$, we say that it is **differentiable\n",
    "everywhere** of simply **differentiable**. If $f$ is differentiable at a given $x$, then it is necessarily continuous at\n",
    "$x$.\n",
    "\n",
    "<div class=\"theorem\"><p>Theorem 1.1. Differentiability implies continuity</p> \n",
    "  <P>If a function $f: \\mathbb{R} \\rightarrow \\mathbb{R}$ is differentiable at a point $x_0$, then it is continuous at $x_0$.\n",
    "  </p>\n",
    "</div>\n",
    "\n",
    "*Proof.* The proof follows from the definition of derivative. We have $$f(x_0 + h) = f(x_0) + f'(x_0)h + o(h) \\quad\n",
    "\\text{as} \\quad h \\to 0.$$ Since $f'(x_0)h + o(h) = o(1)$ as $h \\to 0$, we have that  $$\\lim_{h \\to 0} |f(x_0 + h) -\n",
    "f(x_0)| = 0.$$ Therefore, $f$ is continuous at $x_0$.\n",
    "\n",
    "In addition to enabling the computation of the slope of a function at a point, the derivative provides information about\n",
    "the **mononicity** of $f$ near that point. For example, if $f'(x_0) > 0$, then $f$ is increasing near $x_0$. If $f'(x_0) < 0$,\n",
    "then $f$ is decreasing near $x_0$. If $f'(x_0) = 0$, then $f$ has a local extremum at $x_0$. Such information can be\n",
    "used to develop iterative algorithms to minimize or maximize $f$ by computing iterates of the form $$x_{n+1} = x_n - \\alpha f'(x_n),$$\n",
    "where $\\alpha$ is a step size. If $\\alpha > 0$, the algorithm converges to a local minimum of $f$. If $\\alpha < 0,$ it\n",
    "converges to a local maximum. If $f$ is convex, the algorithm converges to the global minimum. \n",
    "\n",
    "For several elementary functions, the derivative can be computed analytically. \n",
    "\n",
    "<div class=\"example\"><p>Example 1.1. Derivative of power function</p> \n",
    "  <P>The derivative of $f(x) = x^n$ for $x \\in \\mathbb{R}$ and $n \\in \\mathbb{N}\\setminus \\{0\\}$ is given by $f'(x) = nx^{n-1}$. In fact, we consider $f(x) = x^n$ for $x \\in \\mathbb{R}$ and $n \\in \\mathbb{N}\\setminus \\{0\\}$. We have $$\\begin{equation}f(x + h) = (x + h)^n = \\sum_{k=0}^n \\binom{n}{k} x^{n-k} h^k\\end{equation}$$ Therefore, $$\\begin{equation}\\begin{split}f(x + h) - f(x) & = \\sum_{k=0}^n \\binom{n}{k} x^{n-k} h^k - x^n \\\\ & = \\sum_{k=1}^n \\binom{n}{k} x^{n-k} h^k.\\end{split}\\end{equation}$$ Dividing by $h$ and taking the limit as $h \\to 0$, we obtain $$\\begin{equation}\\begin{split}f'(x) & = \\lim_{h \\to 0} \\frac{f(x + h) - f(x)}{h} \\\\ & = \\lim_{h \\to 0} \\sum_{k=1}^n \\binom{n}{k} x^{n-k} h^{k-1} \\\\ & = nx^{n-1}.\\end{split}\\end{equation}$$\n",
    "  </p>\n",
    "</div>\n",
    "<div class=\"remark\"><p>Remark 1.1. Functions on a subset $U$ of $\\mathbb{R}$</p> \n",
    "  <P>For simplicity, we consider functions $f: \\mathbb{R} \\rightarrow \\mathbb{R}.$ However, the concept of derivative can be extended to functions defined on a subset $U$ of $\\mathbb{R}.$ If a fuction $f: U \\rightarrow \\mathbb{R}$ is defined on a subset $U$ of $\\mathbb{R}$, as it is the case for $f(x) = \\sqrt{x}$, defined on $U=\\mathbb{R}^+,$ the derivative of $f$ at a point $x_0 \\in U$ is defined on a neighborhood of $x_0$ contained in $U$, that is, there exist $r > 0$ such that $f$ is differentiable on $x_0 + \\epsilon \\in U$ for all $|\\epsilon| < r.$ The function $f$ is then said **differentiable everywhere** or differentiable for short if it is differentiable at every point in the **interior** of $U$, the set of points in $U$ such that $\\{x + \\epsilon: |\\epsilon| < r\\} \\subset U$ for some $r > 0$. For points lying at the boundary of $U$, the concept of derivative is more subtle and requires the definition of **one-sided derivatives**, meaning that the limit in the definition of derivative is taken from the left or from the right. For example, the derivative of $f(x) = \\sqrt{x}$ at $x=0$ is not defined, since the function is not defined for negative values of $x$. However, the derivative of $f(x) = \\sqrt{x}$ at $x=0$ is defined from the right, and it is equal to $1/2.$</p>\n",
    "</div>\n",
    "\n",
    "### Calculus rules\n",
    "\n",
    "For a given $x \\in \\mathbb{R}$ and two functions $f:\\mathbb{R}\\to\\mathbb{R}$ and $g:\\mathbb{R}\\to \\mathbb{R},$ the\n",
    "derivative of elementary operations on $f$ and $g$ such as their sums, products or compositions can easily be derived\n",
    "from the definition of the derivative, under appropriate conditions on the differentiability properties of $f$ and $g$\n",
    "at $x$. For example, if the functions $f$ and $g$ are differentiable at $x,$ then the sum $af + bg$ and the product $fg$\n",
    "are differentiable at $x$ for any $a, b \\in \\mathbb{R}$, and their derivatives are given by \n",
    "\n",
    "1. Linearity: $(af + bg)'(x) = af'(x) + bg'(x).$\n",
    " \n",
    "2. Product rule: $(fg)'(x) = f'(x)g(x) + f(x)g'(x),$ where $(fg)(x) + f(x)g(x).$\n",
    "\n",
    "The linearity can be verified directly from the linearity of the limit operator. For the product rule, we have\n",
    "\n",
    "<div class=\"non-display-mobile\">\n",
    "$$\\begin{equation}\\begin{split} \\frac{(fg)(x + h) - (fg)(x)}{h} & = \\frac{f(x+h)g(x + h) - \\color{red}{f(x)g(x + h)}}{h} \\\\ & + \\frac{{\\color{red}f(x)g(x + h)} - fg(x)}{h} \\\\ & = g(x + h) \\frac{f(x + h) - f(x)}{h} \\\\ & + f(x)\n",
    "\\frac{g(x + h) - g(x)}{h}.\\end{split}\\end{equation}$$\n",
    "</div>\n",
    "\n",
    "<div class=\"non-display-desktop\">\n",
    "$$\\begin{equation}\\begin{split} & \\frac{(fg)(x + h) - (fg)(x)}{h} = \\\\ & = \\frac{f(x+h)g(x + h) - \\color{red}{f(x)g(x + h)}}{h} \\\\ & + \\frac{{\\color{red}f(x)g(x + h)} - f(x)g(x)}{h} \\\\ & = g(x + h) \\frac{f(x + h) - f(x)}{h} \\\\ & + f(x)\n",
    "\\frac{g(x + h) - g(x)}{h}.\\end{split}\\end{equation}$$\n",
    "</div>\n",
    "\n",
    "If the derivatives of $g$ at $x$ and of $f$ at $g(x)$ exist, then the derivative of the composition $(f\\circ g)(x) =\n",
    "f(g(x))$ at $x$ is given by the **chain rule**:\n",
    "\n",
    "3. Chain rule: $(f\\circ g)'(x) = f'(g(x))g'(x).$\n",
    "\n",
    "The chain rule can be derived by considering the limit of the difference quotient of the composition $(f\\circ g)(x)$ as\n",
    "$h \\to 0$:\n",
    "\n",
    "<div class=\"non-display-mobile\">\n",
    "$$\\begin{equation}\\begin{split} \\frac{(f\\circ g)(x + h) - (f\\circ g)(x)}{h} & = \\frac{f(g(x + h)) - f(g(x))}{h} \\\\ & = \\frac{f(g(x + h)) - f(g(x))}{g(x + h) - g(x)} \\frac{g(x + h) - g(x)}{h}.\\end{split}\\end{equation}$$\n",
    "</div>\n",
    "\n",
    "<div class=\"non-display-desktop\">\n",
    "$$\\begin{equation}\\begin{split} & \\frac{(f\\circ g)(x + h) - (f\\circ g)(x)}{h} = \\\\ & = \\frac{f(g(x + h)) - f(g(x))}{h} \\\\ & = \\frac{f(g(x + h)) - f(g(x))}{g(x + h) - g(x)} \\frac{g(x + h) - g(x)}{h}.\\end{split}\\end{equation}$$\n",
    "</div>\n",
    "\n",
    "As seen in the sequel, the linearity and the product rule can be seen as byproducts of the chain rule, making the chain\n",
    "rule the cornerstone of differentiation.\n",
    "\n",
    "For now, consider a function that can be expressed as sums, products aor compositions of elementary functions such as\n",
    "$f(x) = \\exp(x) \\ln(x) + \\cos x^2.$ Its derivative can be computed by applying the aforementioned rules on the\n",
    "decomposition of $f$ into elementary operations and functions. \n",
    "\n",
    "\n",
    "<div class=\"example\"><p>Example 1.2. Applying rules of differentiation</p> \n",
    "  <P>Consider the function $f(x) = \\exp(x) \\ln(x) + \\cos x^2.$ We have $$f'(x) = \\exp(x) \\ln(x) + \\exp(x) \\frac{1}{x} - 2x \\sin x^2.$$ The derivative of $f$ on $x > 0$ can be computed step by step as follows, denoting $\\operatorname*{sq}(x) := x^2$,\n",
    "\n",
    "  </p>$\n",
    "</div>  \n",
    "\n",
    "````{tip} Theorem: Orthogonal-Projection-Theorem\n",
    "Given $y \\in \\mathbb R^n$ and linear subspace $S \\subset \\mathbb R^n$,\n",
    "there exists a unique solution to the minimization problem\n",
    "\n",
    "```{math}\n",
    "\\hat y := \\argmin_{z \\in S} \\|y - z\\|\n",
    "````\n",
    "\n",
    "\n",
    "adfsfd\n",
    "\n",
    "````{admonition} Definition: Vector Space\n",
    "A vector space is a set V equipped with two operations that satisfy the eight axioms listed below.\n",
    "\n",
    "1. Addition: `+ : V × V → V`\n",
    "2. Scalar multiplication: `· : F × V → V`\n",
    "\n",
    "The eight axioms are...\n",
    "````\n",
    "\n",
    "\n",
    "Algorithm:\n",
    "\n",
    "\n",
    "````{admonition} Algorithm: Bubble Sort\n",
    "Bubble Sort is a simple sorting algorithm that repeatedly steps through the list, compares adjacent elements and swaps them if they are in the wrong order. The pass through the list is repeated until the list is sorted.\n",
    "````\n",
    "\n",
    "\n",
    "\n",
    "Example:\n",
    "\n",
    "````{admonition} Example: Vector Addition\n",
    "Consider two vectors `v = (1, 2, 3)` and `w = (4, 5, 6)`. The addition of `v` and `w` is a vector `z = (5, 7, 9)`.\n",
    "````\n",
    "\n",
    "\n",
    "\n",
    "Remark:\n",
    "\n",
    "\n",
    "````{admonition} Remark: Note on Vector Spaces\n",
    "Note that the set of all vectors in a vector space can be infinite, and the operations of addition and scalar multiplication must be defined for all vectors in the space.\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}