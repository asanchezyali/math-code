{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diferenciación\n",
    "\n",
    "En este capítulo, revisamos conceptos clave de diferenciación. En particular, enfatizamos en el papel fundamental que desempeñan las aproximaciones lineales en el contexto de la diferenciación numérica. También discutimos el concepto de diferenciación automática, que es una herramienta poderosa para calcular derivadas de funciones implementadas en programas de computadora.\n",
    "\n",
    "## Derivadas de funciones univariadas\n",
    "### Derivadas y continuidad\n",
    "Antes de estudiar las derivadas, recordamos la definición de continuidad de una función.\n",
    "\n",
    "<div class=\"definition\"><p>Definición 1.1. Función continua</p> \n",
    "  Una función $f: \\mathbb{R} \\rightarrow \\mathbb{R}$ es **continua en un punto** $x_0$ si $$\\lim_{x \\to x_0} f(x) = f(x_0).$$ Una función $f$ es **continua** si es continua en cada punto de su dominio.\n",
    "</div>\n",
    "\n",
    "En lo siguiente, usamos la notación de Landau para describir el comportamiento de las funciones cerca de un punto.\n",
    "Escribimos $$f(x) = o\\big(g(x)\\big) \\quad \\text{cuando} \\quad x \\to x_0$$\n",
    "si $$\\lim_{x \\to x_0} \\frac{|f(x)|}{|g(x)|} = 0.$$\n",
    "\n",
    "Es decir, $f(x)$ es mucho más pequeño que $g(x)$ a medida que $x$ se acerca a $x_0.$ Por ejemplo, $f$ es continua en $x_0$ si $$f(x_0 + \\delta) = f(x_0) + o(1) \\quad \\text{as} \\quad \\delta \\to 0.$$\n",
    "\n",
    "Ahora introducimos el concepto de derivada. Consideremos una función $f: \\mathbb{R} \\rightarrow \\mathbb{R}$ y un punto\n",
    "$x_0$ en su dominio. Su valor en un intervalo $[x_0, x_0 + h]$ puede aproximarse mediante la sencante entre $\\big(x_0,\n",
    "f(x_0)\\big)$ y $\\big(x_0 + h, f(x_0 + h)\\big)$. La pendiente de esta **secante** está dada por el cociente diferencial\n",
    "$$\\frac{f(x_0 + h) - f(x_0)}{h}.$$ En el limite de un infinitesimal $h$, la secante converge a la **tangente** en\n",
    "$\\big(x_0, f(x_0)\\big)$. La pendiente de esta tangente es la derivada de $f$ en $x_0$, denotada por $f'(x_0).$ La\n",
    "definición formal de la derivada es la siguiente.\n",
    "\n",
    "<div class=\"definition\"><p>Definición 1.2. Derivada</p>\n",
    "  La **derivada** de una función $f: \\mathbb{R} \\rightarrow \\mathbb{R}$ en un punto $x_0$ está definida como \n",
    "  $$f'(x_0) = \\lim_{h \\to 0} \\frac{f(x_0 + h) - f(x_0)}{h}.$$ Si $f'(x_0)$ está bien definida well-defined en $x_0$, en particular, si el límite existe, decimos que la función $f$ es **diferenciable** en $x_0$.\n",
    "</div>\n",
    "\n",
    "Aquí, y en las definiciones siguientes, si $f$ es diferenciable en cualquier $x$, decimos que es **diferenciable en todas partes** o simplemente **diferenciable**. Si $f$ es diferenciable en un punto dado $x$, entonces es necesariamente continua en $x$.\n",
    "\n",
    "<div class=\"theorem\"><p>Teorema 1.1. Diferenciabilidad implica continuidad</p> \n",
    "  Si una función $f: \\mathbb{R} \\rightarrow \\mathbb{R}$ es diferenciable en un punto $x_0$, entonces es continua en $x_0$.\n",
    "</div>\n",
    "\n",
    "**Demostración.** La prueba sigue de la definición de derivada. Tenemos $$f(x_0 + h) = f(x_0) + f'(x_0)h + o(h) \\quad \\text{cuando} \\quad h \\to 0.$$ Dado que $f'(x_0)h + o(h) = o(1)$ cuando $h \\to 0$, tenemos que $$\\lim_{h \\to 0} |f(x_0 + h) - f(x_0)| = 0.$$ Por lo tanto, $f$ es continua en $x_0$.\n",
    "\n",
    "Además de permitir el cálculo de la pendiente de una función en un punto, la derivada proporciona información sobre la\n",
    "**monotonía** de $f$ cerca de ese punto. Por ejemplo, si $f'(x_0) > 0$, entonces $f$ es creciente cerca de $x_0$. Si\n",
    "$f'(x_0) < 0$, entonces $f$ es decreciente cerca de $x_0$. Si $f'(x_0) = 0$, entonces $f$ tiene un extremo local en\n",
    "$x_0$. Esta información puede usarse para desarrollar algoritmos iterativos para minimizar o maximizar $f$ calculando\n",
    "iterados de la forma $$x_{n+1} = x_n - \\alpha f'(x_n),$$ donde $\\alpha$ es un tamaño de paso. Si $\\alpha > 0$, el\n",
    "algoritmo converge a un mínimo local de $f$. Si $\\alpha < 0,$ converge a un máximo local. Si $f$ es convexa, el\n",
    "algoritmo converge al mínimo global.\n",
    "\n",
    "Para varias funciones elementales, la derivada se puede calcular analíticamente.\n",
    "\n",
    "<div class=\"example\"><p>Ejemplo 1.1. Derivada de una función potencia</p> \n",
    "  La derivada de $f(x) = x^n$ para $x \\in \\mathbb{R}$ y $n \\in \\mathbb{N}\\setminus \\{0\\}$ está dada por $f'(x) = nx^{n-1}$. De hecho, consideramos $f(x) = x^n$ para $x \\in \\mathbb{R}$ y $n \\in \\mathbb{N}\\setminus \\{0\\}$. Tenemos $$\\begin{equation}f(x + h) = (x + h)^n = \\sum_{k=0}^n \\binom{n}{k} x^{n-k} h^k\\end{equation}$$ Por lo tanto, $$\\begin{equation}\\begin{split}f(x + h) - f(x) & = \\sum_{k=0}^n \\binom{n}{k} x^{n-k} h^k - x^n \\\\ & = \\sum_{k=1}^n \\binom{n}{k} x^{n-k} h^k.\\end{split}\\end{equation}$$ Dividiendo por $h$ y tomando el límite cuando $h \\to 0$, obtenemos $$\\begin{equation}\\begin{split}f'(x) & = \\lim_{h \\to 0} \\frac{f(x + h) - f(x)}{h} \\\\ & = \\lim_{h \\to 0} \\sum_{k=1}^n \\binom{n}{k} x^{n-k} h^{k-1} \\\\ & = nx^{n-1}.\\end{split}\\end{equation}$$\n",
    "</div>\n",
    "<div class=\"remark\"><p>Observación 1.1. Funciones en un subconjunto $U$ de $\\mathbb{R}$</p> \n",
    "  Para simplificar, consideramos funciones $f: \\mathbb{R} \\rightarrow \\mathbb{R}.$ Sin embargo, el concepto de derivada se puede extender a funciones definidas en un subconjunto $U$ de $\\mathbb{R}.$ Si una función $f: U \\rightarrow \\mathbb{R}$ está definida en un subconjunto $U$ de $\\mathbb{R}$, como es el caso de $f(x) = \\sqrt{x}$, definida en $U=\\mathbb{R}^+,$ la derivada de $f$ en un punto $x_0 \\in U$ está definida en un vecindario de $x_0$ contenido en $U$, es decir, existen $r > 0$ tal que $f$ es diferenciable en $x_0 + \\epsilon \\in U$ para todo $|\\epsilon| < r.$ La función $f$ se dice entonces **diferenciable en todas partes** o diferenciable en resumen si es diferenciable en cada punto en el **interior** de $U$, el conjunto de puntos en $U$ tal que $\\{x + \\epsilon: |\\epsilon| < r\\} \\subset U$ para algún $r > 0$. Para puntos que yacen en el borde de $U$, el concepto de derivada es más sutil y requiere la definición de **derivadas unilaterales**, lo que significa que el límite en la definición de derivada se toma desde la izquierda o desde la derecha. Por ejemplo, la derivada de $f(x) = \\sqrt{x}$ en $x=0$ no está definida, ya que la función no está definida para valores negativos de $x$. Sin embargo, la derivada de $f(x) = \\sqrt{x}$ en $x=0$ está definida desde la derecha, y es igual a $1/2.$\n",
    "</div>\n",
    "\n",
    "### Reglas del cálculo\n",
    "Para un $x \\in \\mathbb{R}$ dado y dos funciones $f:\\mathbb{R}\\to\\mathbb{R}$ y $g:\\mathbb{R}\\to \\mathbb{R},$ la derivada\n",
    "de operaciones elementales en $f$ y $g$ como sus sumas, productos o composiciones se pueden derivar fácilmente de la\n",
    "definición de derivada, bajo condiciones apropiadas sobre las propiedades de diferenciabilidad de $f$ y $g$ en $x$. Por\n",
    "ejemplo, si las funciones $f$ y $g$ son diferenciables en $x,$ entonces la suma $af + bg$ y el producto $fg$ son\n",
    "diferenciables en $x$ para cualquier $a, b \\in \\mathbb{R}$, y sus derivadas están dadas por\n",
    "\n",
    "1. Linealidad: $(af + bg)'(x) = af'(x) + bg'(x).$\n",
    "2. Regla del producto: $(fg)'(x) = f'(x)g(x) + f(x)g'(x),$ donde $(fg)(x) + f(x)g(x).$\n",
    "\n",
    "La linealidad se puede verificar directamente a partir de la linealidad del operador de límite. Para la regla del\n",
    "producto, tenemos\n",
    "\n",
    "<div class=\"non-display-mobile\">\n",
    "$$\\begin{equation}\\begin{split} \\frac{(fg)(x + h) - (fg)(x)}{h} & = \\frac{f(x+h)g(x + h) - \\color{red}{f(x)g(x + h)}}{h} \\\\ & + \\frac{{\\color{red}f(x)g(x + h)} - fg(x)}{h} \\\\ & = g(x + h) \\frac{f(x + h) - f(x)}{h} \\\\ & + f(x)\n",
    "\\frac{g(x + h) - g(x)}{h}.\\end{split}\\end{equation}$$\n",
    "</div>\n",
    "\n",
    "<div class=\"non-display-desktop\">\n",
    "$$\\begin{equation}\\begin{split} & \\frac{(fg)(x + h) - (fg)(x)}{h} = \\\\ & = \\frac{f(x+h)g(x + h) - \\color{red}{f(x)g(x + h)}}{h} \\\\ & + \\frac{{\\color{red}f(x)g(x + h)} - f(x)g(x)}{h} \\\\ & = g(x + h) \\frac{f(x + h) - f(x)}{h} \\\\ & + f(x)\n",
    "\\frac{g(x + h) - g(x)}{h}.\\end{split}\\end{equation}$$\n",
    "</div>\n",
    "\n",
    "Si las derivadas de $g$ en $x$ y de $f$ en $g(x)$ existen, entonces la derivada de la composición $(f\\circ g)(x) =\n",
    "f(g(x))$ en $x$ está dada por la **regla de la cadena**:\n",
    "\n",
    "3. Regla de la cadena: $(f\\circ g)'(x) = f'(g(x))g'(x).$\n",
    "\n",
    "La regla de la cadena se puede derivar considerando el límite del cociente de la composición $(f\\circ g)(x)$ a medida\n",
    "que $h \\to 0$:\n",
    "\n",
    "<div class=\"non-display-mobile\">\n",
    "$$\\begin{equation}\\begin{split} \\frac{(f\\circ g)(x + h) - (f\\circ g)(x)}{h} & = \\frac{f(g(x + h)) - f(g(x))}{h} \\\\ & = \\frac{f(g(x + h)) - f(g(x))}{g(x + h) - g(x)} \\frac{g(x + h) - g(x)}{h}.\\end{split}\\end{equation}$$\n",
    "</div>\n",
    "\n",
    "<div class=\"non-display-desktop\">\n",
    "$$\\begin{equation}\\begin{split} & \\frac{(f\\circ g)(x + h) - (f\\circ g)(x)}{h} = \\\\ & = \\frac{f(g(x + h)) - f(g(x))}{h} \\\\ & = \\frac{f(g(x + h)) - f(g(x))}{g(x + h) - g(x)} \\frac{g(x + h) - g(x)}{h}.\\end{split}\\end{equation}$$\n",
    "</div>\n",
    "\n",
    "Como se puede ver, la linealidad y la regla del producto son consecuencias de la regla de la cadena, lo que hace que la\n",
    "regla de la cadena sea la piedra angular de la diferenciación.\n",
    "\n",
    "Por ahora, consideremos una función que se puede expresar como sumas, productos o composiciones de funciones elementales\n",
    "como $f(x) = \\exp(x) \\ln(x) + \\cos x^2.$ Su derivada se puede calcular aplicando las reglas mencionadas anteriormente a\n",
    "la descomposición de $f$ en operaciones y funciones elementales.\n",
    "\n",
    "<div class=\"example\"><p>Ejemplo 1.2. Aplicación de las reglas de diferenciación</p> \n",
    "  Consideremos la función $f(x) = \\exp(x) \\ln(x) + \\cos x^2.$ Tenemos $$f'(x) = \\exp(x) \\ln(x) + \\exp(x) \\frac{1}{x} - 2x \\sin x^2.$$ La derivada de $f$ en $x > 0$ se puede calcular paso a paso de la siguiente manera, denotando $\\operatorname*{sq}(x) := x^2,$\n",
    "  $$\\begin{equation}\\begin{split}f'(x) &  = (\\exp \\cdot \\ln)'(x) + (\\cos \\circ \\operatorname*{sq})'(x) \\\\ & = \\exp'(x) \\ln(x) + \\exp(x) \\ln'(x) + \\cos'(\\operatorname*{sq}(x)) \\operatorname*{sq}'(x) \\\\ & = \\exp(x) \\ln(x) + \\exp(x) \\frac{1}{x} - 2x \\sin x^2.\\end{split}\\end{equation}$$\n",
    "</div>\n",
    "\n",
    "### Notación de Leibniz\n",
    "La noción de derivada fue introducida por Isaac Newton y Gottfried Wilhelm Leibniz de forma independiente en el siglo\n",
    "XVIII. Este último consideró las derivadas como el cociente de variaciones infinitesimales. Es decir, denotando $y =\n",
    "f(x)$ una variable que depende de $x$ a través de $f$, Leibniz consideró la derivada de $f$ como el cociente:\n",
    "\n",
    "$$f' = \\frac{dy}{dx} \\quad \\text{con} \\quad f'(x) = \\left. \\frac{df}{dx}\\\\\\right|_{x}.$$\n",
    "\n",
    "Aquí, $dy$ y $dx$ son variaciones infinitesimales de $y$ y $x$, respectivamente, y el símbolo $\\left.\n",
    "\\frac{df}{dx}\\\\\\right|_{x}$ denota la derivada de $f$ en $x$. La notación $\\frac{dy}{dx}$ se llama **notación de\n",
    "Leibniz**. Es particularmente útil para expresar la regla de la cadena, ya que permite expresar la derivada de una\n",
    "composición de funciones como el producto de las derivadas de las funciones involucradas en la composición. Si tenemos\n",
    "para $z = g(y)$ y $y = f(x)$, entonces la regla de la cadena se puede expresar como:\n",
    "\n",
    "$$\\frac{dz}{dx} = \\frac{dz}{dy} \\frac{dy}{dx}.$$\n",
    "\n",
    "Esto sugiere que las derivadas se multiplican al considerar composiciones de funciones. En la evaluación, la regla de la\n",
    "cadena en la notación de Leibniz recupera la fórmula presentada anteriormente como\n",
    "\n",
    "$$\\left. \\frac{dz}{dx}\\\\\\right|_{x} = \\left. \\frac{dz}{dy}\\\\\\right|_{y} \\left. \\frac{dy}{dx}\\\\\\right|_{x} =\n",
    "g'(f(x))f'(x) = (g\\circ f)'(x).$$\n",
    "\n",
    "## Funciones multivariables\n",
    "### Derivadas direccionales\n",
    "Consideremos ahora una función $f: \\mathbb{R}^n \\rightarrow \\mathbb{R}$ de múltiples entradas $x = (x_1, \\ldots, x_n)\n",
    "\\in \\mathbb{R}^n$. El ejemplo más importante en el aprendizaje automático es una función que, a los parámetros\n",
    "$x\\in\\mathbb{R}^n$ de una red neuronal, asocia el valor de pérdida en $\\mathbb{R}$. Las variaciones de $f$ deben\n",
    "definirse a lo largo de direcciones específicas en $\\mathbb{R}^n$, como la variación $f(x + \\delta v) - f(x)$ de $f$\n",
    "alrededor de $x\\in\\mathbb{R}^n$ en la dirección $v\\in\\mathbb{R}^n$. Esta consideración conduce naturalmente a la\n",
    "definición de la derivada direccional de $f$ en $x$ en la dirección $v$.\n",
    "\n",
    "<div class=\"definition\"><p>Definición 1.3. Derivada direccional</p>\n",
    "  La **derivada direccional** de una función $f: \\mathbb{R}^n \\rightarrow \\mathbb{R}$ en un punto $x \\in \\mathbb{R}^n$ en la dirección $v \\in \\mathbb{R}^n$ se define como $$\\partial f(x)[v] = \\lim_{h \\to 0} \\frac{f(x + hv) - f(x)}{h}.$$ Si el límite existe, decimos que $f$ es diferenciable en $x$ en la dirección $v$.\n",
    "</div>\n",
    "\n",
    "Un ejemplo de derivada direccional consiste en calcular la derivada de una función $f$ en un punto $x$ en cualquiera de\n",
    "las direcciones canónicas $e_i$ de $\\mathbb{R}^n$, donde $e_i$ es el vector con un $1$ en la posición $i$ y $0$ en las\n",
    "demás.\n",
    "\n",
    "Esto nos permite definir la noción de **derivadas parciales**, denotadas para $i = 1, \\ldots, n$ por $$\\partial_i f(x)\n",
    ":= \\partial f(x)[e_i] = \\lim_{h \\to 0} \\frac{f(x + he_i) - f(x)}{h}.$$\n",
    "\n",
    "Esto también se denota en la notación de Leibniz por $\\partial_i f(x) = \\frac{\\partial f}{\\partial x_i}(x)$ o\n",
    "$\\partial_i f(x) = \\partial_{x_i} f(x).$ Al moverse solo a lo largo de la $i$-ésima coordenada de la función, la\n",
    "derivada parcial es similar a usar la función $\\phi(x_i)=f(x_1, \\cdots, x_n)$ alrededor de $x_i$, dejando todas las\n",
    "otras coordenadas fijas en sus valores $x_i$.\n",
    "\n",
    "### Gradientes\n",
    "Introducimos ahora el vector gradiente, que reúne las derivadas parciales. Primero recordamos las definiciones de mapa y\n",
    "forma lineal.\n",
    "\n",
    "<div class=\"definition\"><p>Definición 1.4. Mapa lineal, forma lineal</p>\n",
    "  Un **mapa lineal** $A: \\mathbb{R}^n \\rightarrow \\mathbb{R}^m$ es una función que satisface las siguientes propiedades para todo $x, y \\in \\mathbb{R}^n$ y $\\alpha, \\beta \\in \\mathbb{R}$: $$A(\\alpha x + \\beta y) = \\alpha A(x) + \\beta A(y).$$ Una **forma lineal** es un mapa lineal $A: \\mathbb{R}^n \\rightarrow \\mathbb{R}$.\n",
    "</div>\n",
    "\n",
    "La linealidad juega un papel crucial en la diferenciabilidad de una función.\n",
    "\n",
    "<div class=\"definition\"><p>Definición 1.5. Diferenciabilidad, caso de una sola salida</p>\n",
    "  Una función $f:\\mathbb{R}^{n}\\to \\mathbb{R}$ es diferenciable en $x\\in \\mathbb{R}$ si su derivada direccional está definida en cualquier dirección $v\\in\\mathbb{R}^n$, es lineal en cualquier dirección, y si\n",
    "  $$\\lim_{||v||_{2}\\to 0}\\frac{|f(x + v) - f(x) - \\partial f(x)[v]|}{||v||_{2}} = 0$$\n",
    "</div>\n",
    "\n",
    "Ahora podemos introducir el gradiente.\n",
    "\n",
    "<div class=\"definition\"><p>Definición 1.6. Gradiente</p>\n",
    "  El **gradiente** de una función diferenciable $f:\\mathbb{R}^n\\to \\mathbb{R}$ en un punto $x\\in\\mathbb{R}^n$ se define como el vector de derivadas parciales\n",
    "  $$\\nabla f(x) = \\begin{pmatrix} \\partial_1 f(x) \\\\ \\vdots \\\\ \\partial_n f(x) \\end{pmatrix} = \\begin{pmatrix} \\partial f(x)[e_1] \\\\ \\vdots \\\\ \\partial f(x)[e_n] \\end{pmatrix}.$$\n",
    "  Por linealidad, la derivada direccional de $f$ en $x$ en la dirección $v=\\sum_{i=1}^n v_i e_i$ está dada por\n",
    "  $$\\partial f(x)[v] = \\sum_{i=1}^n v_i\\partial_i f(x)[e_i] = \\langle v, \\nabla f(x) \\rangle.$$\n",
    "</div>\n",
    "\n",
    "En la definición anterior, el hecho de que el gradiente se pueda usar para calcular la derivada direccional es una mera\n",
    "consecuencia de la linealidad. Sin embargo, en casos más abstractos presentados en secciones posteriores, el gradiente\n",
    "se\n",
    "define a través de esta propiedad.\n",
    "\n",
    "Como ejemplo simple, cualquier función lineal de la forma $f(x)=a^\\top x = \\sum_{i=1}^{n}a_i x_i$ es diferenciable ya\n",
    "que tenemos $(a^\\top(x+v) - a^\\top x - a^\\top v)/||v||_2 = 0$ para cualquier $v$ y en particular para $||v||\\to 0.$\n",
    "Además, su gradiente se define naturalmente como $\\nabla f(x) = a.$\n",
    "\n",
    "Generalmente, para mostrar que una función es diferenciable y encontrar su gradiente, un enfoque es aproximar $f(x+v)$\n",
    "alrededor de $v=0$. Si podemos encontrar un vector $g$ tal que $$f(x+v) = f(x) + \\langle g, v\\rangle + o(||v||_2),$$\n",
    "entonces $f$ es diferenciable en $x$ ya que $\\langle g, \\cdot \\rangle$ es lineal. Además, $g$ es entonces el gradiente\n",
    "de $f$ en $x$.\n",
    "\n",
    "<div class=\"remark\"><p>Observación 1.2. Diferenciabilidad de Gateux y Fréchet</p> \n",
    "  Existen múltiples definiciones de diferenciabilidad. La presentada en la Definición 1.5 es sobre funciones **Fréchet\n",
    "  diferenciables**. Alternativamente, si $f:\\mathbb{R}^p \\to \\mathbb{R}$ tiene derivadas direccionales bien definidas\n",
    "  a lo largo de cualquier dirección, entonces la función es **Gateaux diferenciable**. Tenga en cuenta que la existencia\n",
    "  de derivadas direccionales en cualquier dirección no es una condición suficiente para que la función sea diferenciable.\n",
    "  En otras palabras, cualquier función Fréchet diferenciable es Gateaux diferenciable, pero el recíproco no es cierto. Como\n",
    "  contraejemplo, uno puede verificar que la función\n",
    "  $$f(x_1, x_2)=\\frac{x_1^3}{x_1^2 + x_2^2}$$ es Gateaux diferenciable en $0$ pero no Fréchet diferenciable en $0$\n",
    "  (porque la derivada direccional en 0 no es lineal).\n",
    "\n",
    "  Algunos autores también requieren que las funciones Gateux diferenciables tengan derivadas direccionales lineales a lo\n",
    "  largo de cualquier dirección. Estas aún no son funciones Fréchet diferenciables. De hecho, el límite en la Definición\n",
    "  1.5 es sobre cualquier vector que tienda a 0 (potencialmente de una manera patológica), mientras que las derivadas\n",
    "  direccionales consideran tales límites de manera única en términos de una sola dirección.\n",
    "\n",
    "  En el resto de este capítulo, todas las definiciones de diferenciabilidad son en términos de diferenciabilidad de\n",
    "  Fréchet.\n",
    "</div>\n",
    "\n",
    "El Ejemplo 1.3 ilustra cómo calcular el gradiente de la pérdida logística y validar su diferenciabilidad.\n",
    "\n",
    "<div class=\"example\"><p>Ejemplo 1.3. Gradiente de la pérdida logística</p> \n",
    "  Consideremos la pérdida logística\n",
    "  $$l(\\theta, y) := -y^\\top \\theta + \\log\\left(\\sum_{k=1}^m \\exp(\\theta_k)\\right),$$\n",
    "  que mide el error de predicción de los logits $\\theta\\in\\mathbb{R}^m$ para un objetivo $y\\in\\{e_1, \\ldots, e_m\\}.$\n",
    "  Calculemos el gradiente de esta pérdida. Queremos calcular el gradiente de $f(\\theta):=l(\\theta, y).$ Descompongamos\n",
    "  $f$ como $f = f + \\operatorname*{logsumexp}$ con $l(\\theta):=\\langle -y, \\theta\\rangle$ y $$\\operatorname*{logsumexp}(\\theta) := \\log\\left(\\sum_{k=1}^m \\exp(\\theta_k)\\right),$$ la función log-sum-exp. La función $l$ es lineal, por lo que es diferenciable con gradiente $\\nabla l(\\theta) = -y.$ Nos enfocamos entonces en $\\operatorname*{logsumexp}.$ Denotando $\\exp(\\theta) = (\\exp(\\theta_1), \\ldots, \\exp(\\theta_m)),$ tenemos\n",
    "  $$\\begin{equation}\\nabla \\operatorname*{logsumexp}(\\theta) = \\frac{\\exp(\\theta)}{\\sum_{k=1}^m \\exp(\\theta_k)} = \\operatorname*{softmax}(\\theta),\\end{equation}$$\n",
    "  donde $\\operatorname*{softmax}(\\theta)$ es la función softmax. El gradiente de la pérdida logística está dado por\n",
    "  $$\\nabla l(\\theta) = -y + \\operatorname*{softmax}(\\theta).$$\n",
    "</div>\n",
    "\n",
    "### Linealidad de los gradientes\n",
    "La noción de diferenciabilidad para funciones de múltiples entradas hereda naturalmente de la linealidad de las\n",
    "derivadas para funciones de una sola entrada. Para cualquier $u_1, \\dots, u_n\\in\\mathbb{R}$ y cualquier función de\n",
    "varias entradas $f_1, \\dots f_n$ que son diferenciables en $x\\in\\mathbb{R}^n$, la función $f(x) = \\sum_{i=1}^n u_i\n",
    "f_i(x)$ es diferenciable en $x$ con gradiente $\\nabla f(x) = \\sum_{i=1}^n u_i \\nabla f_i(x).$ Esta propiedad es una\n",
    "consecuencia directa de la linealidad del gradiente.\n",
    "\n",
    "<div class=\"theorem\"><p>Teorema 1.2. Linealidad de los gradientes</p>\n",
    "  Sea $f_1, \\ldots, f_n:\\mathbb{R}^n\\to\\mathbb{R}$ funciones diferenciables en $x\\in\\mathbb{R}^n$ y $u_1, \\ldots, u_n\\in\\mathbb{R}$. Entonces la función $f(x) = \\sum_{i=1}^n u_i f_i(x)$ es diferenciable en $x$ con gradiente $\\nabla f(x) = \\sum_{i=1}^n u_i \\nabla f_i(x).$\n",
    "</div>\n",
    "\n",
    "El gradiente define la dirección de ascenso más empinada de una función. Para ver por qué, observe que\n",
    "$$\\operatorname*{argmax}_{v\\in\\mathbb{R}^n, ||v||_2\\leq 1} \\partial f(x)[v] = \\operatorname*{argmax}_{v\\in\\mathbb{R}^n,\n",
    "||v||_2\\leq 1} \\langle v, \\nabla f(x)\\rangle = \\frac{\\nabla f(x)}{||\\nabla f(x)||_2},$$ donde asumimos que $\\nabla\n",
    "f(x)\\neq 0$ para evitar la división por cero. El gradiente $\\nabla f(x)$ es ortogonal al conjunto de nivel de la función\n",
    "$f$ en $x$, lo que significa que el gradiente apunta en la dirección del ascenso más empinado de $f$ en $x$. Por el\n",
    "contrario, el gradiente negativo $-\\nabla f(x)$ apunta en la dirección del descenso más empinado de $f$ en $x$. Esta\n",
    "observación motiva el desarrollo de algoritmos de optimización como el descenso de gradiente, que actualiza\n",
    "iterativamente los parámetros $x$, $x_{n+1} = x_n - \\alpha \\nabla f(x_n),$ donde $\\alpha > 0$ es un tamaño de paso. Por\n",
    "lo tanto, busca el mínimo de $f$ siguiendo la dirección de descenso más empinada.\n",
    "\n",
    "### Jacobianos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
